---
title: "CS231n 学习总结"
tags: compute-vision deep-learning

article_header:
  type: cover
  image:
    src: /assets/images/post_images/cs231n/title.png
---

## 背景

寒假里草草看了CS231n，此为学习笔记以及相关概念的拓展。

<!--more-->
## 优化部分的相关算法

### 三种梯度下降

1. Gradient decent 
每次更新时使用全部样本。

2. Stochastic gradient descent 
每次更新时使用一个样本。

3. mini-batch gradient descent
每次更新时使用一批样本。

### Batch Normalization

大意是将每一层输入归一化，然后加入$\gamma$与$\beta$缩放与偏移后，喂给网络，有效解决梯度弥散和梯度爆炸的问题。

BN层一般是在激活层之后，全连接层之前。

![bn](/assets/images/post_images/cs231n/bn.png)
### Adam 